{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"158059a190b2420d9cb80a65ae933eba","source_hash":"d73fd03b","execution_start":1655574997409,"execution_millis":12,"deepnote_cell_height":441,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom utils import graph_overfit\n\nimport numpy as np\nimport pandas as pd\nimport dill as pkl\nimport os\nimport matplotlib.pyplot as plt\nimport tqdm\n\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\ntorch.manual_seed(seed=73)\nnp.random.seed(seed=73)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","block_group":"158059a190b2420d9cb80a65ae933eba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e0ada4a8e6184be1b04ebf6dd814d9fb","source_hash":"f5604853","is_code_hidden":false,"execution_start":1655576958355,"execution_millis":1,"deepnote_cell_height":603,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"X_train = np.load(os.path.join('data', 'X_train_transformed.npy'), allow_pickle=True)\ny_train = np.load(os.path.join('data', 'y_train.pkl'), allow_pickle=True)\nX_test = np.load(os.path.join('data', 'X_test_transformed.npy'), allow_pickle=True)\ny_test = np.load(os.path.join('data', 'y_test.pkl'), allow_pickle=True)\n\nX_folds = np.load(os.path.join('data', 'X_folds_tuple.npy'), allow_pickle=True)\ny_folds = np.load(os.path.join('data', 'y_folds_tuple.npy'), allow_pickle=True)\nfold_ids = [(np.array(fold.index)) for fold in X_folds]\n\nX_tensor = torch.tensor(X_train.astype(np.float32))\ny_train -= 1\ny_tensor = torch.tensor(y_train.values).type(torch.LongTensor)\n\ntrain_data = TensorDataset(X_tensor, y_tensor)\n\nX_test_tensor = torch.tensor(X_test.astype(np.float32))\ny_test -= 1\ny_test_tensor = torch.tensor(y_test.values).type(torch.LongTensor)\n\ntest_data = TensorDataset(X_test_tensor, y_test_tensor)\n\ntrain_loader = DataLoader(train_data,\n                        shuffle=True,\n                        batch_size=32,\n                        num_workers=0)\n\ntest_loader = DataLoader(test_data,\n                        shuffle=True,\n                        batch_size=16,\n                        num_workers=0)","block_group":"e0ada4a8e6184be1b04ebf6dd814d9fb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"50e52016ada54b189b927c340b879fed","source_hash":"86015248","is_code_hidden":false,"execution_start":1655572391239,"execution_millis":1,"deepnote_cell_height":171,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def custom_cv_folds(fold_ids):\n    fold_ids = np.array(fold_ids, dtype=object)\n    for n in range(len(fold_ids)):\n        all_ids = list(range(len(fold_ids)))\n        all_ids.remove(n)\n        yield np.concatenate(fold_ids[all_ids]), fold_ids[n]","block_group":"50e52016ada54b189b927c340b879fed","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2343e13b9d3741d89caf0b996348def9","source_hash":"17679790","is_code_hidden":false,"execution_start":1655572393266,"execution_millis":2,"deepnote_cell_height":279,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def plot_training(train_vals, test_vals, base_vals):\n    fig, axs = plt.subplots(3,1, figsize=(10, 15))\n    titles = ['Loss', 'Accuracy', 'Revenue']\n    for n, (title, train, test, base) in enumerate(zip(titles, train_vals, test_vals, base_vals)):\n        axs[n].plot(train, label='train')\n        axs[n].plot(test, label='test')\n        axs[n].plot(base, label='base')\n        axs[n].set_title(title)\n        axs[n].legend()\n\n    plt.legend()\n    plt.show()","block_group":"2343e13b9d3741d89caf0b996348def9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"26a37105639443be82c6277b98842206","source_hash":"e6c34f42","is_code_hidden":false,"execution_start":1655572394807,"execution_millis":2,"deepnote_cell_height":207,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def calculate_revenue(predictions, targets, cost_matrix= torch.tensor([\n                                                        [5, -5, -5, 2],\n                                                        [-5, 10, 2, -5],\n                                                        [-5, 2, 10, -5],\n                                                        [2, -5, -2, 5]\n                                                        ], device=device)):\n    winners = predictions.argmax(dim=1)\n    return torch.sum(cost_matrix[targets, winners])","block_group":"26a37105639443be82c6277b98842206","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b88929ef47df45dc9f3ccf6817266a65","source_hash":"cec56f3b","is_code_hidden":false,"execution_start":1655578262807,"execution_millis":6,"deepnote_cell_height":369,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"class CostSensitiveRegularizedLoss(nn.Module):\n    def __init__(self, cost_matrix, lambd, reduction='mean'):\n        super(CostSensitiveRegularizedLoss, self).__init__()\n        self.cost_matrix = (-1.)*cost_matrix\n        self.base_loss = torch.nn.CrossEntropyLoss()\n        self.lambd = lambd\n        self.reduction = reduction\n    \n    def forward(self, outputs, labels):\n        base_l = self.base_loss(outputs, labels)\n        cost_l = (self.cost_matrix[labels]*outputs.float()).sum(dim=-1)\n        if self.reduction == 'mean':\n            total_l = base_l + self.lambd * cost_l.mean()\n        elif self.reduction == 'sum':\n            total_l = base_l + self.lambd * cost_l.sum()\n\n        return total_l","block_group":"b88929ef47df45dc9f3ccf6817266a65","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1b2592cf67fa489590d4f9ac5bfece05","source_hash":"87416994","execution_start":1655577333087,"execution_millis":0,"deepnote_cell_height":477,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"class nn_classifier(nn.Module):\n    def __init__(self, n_features=99):\n        super(nn_classifier, self).__init__()\n\n        self.input_layer = nn.Linear(n_features, 128)\n        self.input_activation = nn.SELU()\n\n        self.hidden_layers = nn.Sequential(\n            nn.Linear(128, 64),\n            nn.AlphaDropout(p=0.1),\n            nn.SELU(),\n            nn.Linear(64, 32),\n            nn.AlphaDropout(p=0.1),\n            nn.Linear(32, 4)\n        )\n\n        self.output_layer = nn.LogSoftmax(1)\n\n    def forward(self, x):\n        x = self.input_activation(self.input_layer(x))\n        x = self.hidden_layers(x)\n        output = self.output_layer(x)\n        return output","block_group":"1b2592cf67fa489590d4f9ac5bfece05","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"24d2ffd054c84ff38bf272a00eb43d6d","source_hash":"b216b723","execution_start":1655572400849,"execution_millis":2,"deepnote_cell_height":225,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"class BaselineClassifier(nn.Module):\n    def __init__(self, y):\n        super(BaselineClassifier, self).__init__()\n        self.prediction = torch.mode(y)[0]\n\n    def forward(self, x):\n        output = torch.zeros((len(x), 4))\n        output[:, self.prediction] = 1.\n        return output","block_group":"24d2ffd054c84ff38bf272a00eb43d6d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"ba372b7fb8104ee38d926b414229fd6d","source_hash":"e5176739","execution_start":1655578140651,"execution_millis":0,"deepnote_cell_height":1107,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def train(model: nn.Module, data_loader: DataLoader, optimizer: torch.optim.Optimizer, loss_function: nn.modules.loss, device: torch.device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    revenue = 0\n\n    for data in data_loader:\n        inp, target = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        output = model(inp)\n        #print(output)\n\n        loss = loss_function(output, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss\n\n        winners = output.argmax(dim=1)\n        correct += torch.sum((winners == target))\n        total += len(target)\n        revenue += calculate_revenue(output, target)\n\n    #out_loss = running_loss / len(data_loader)\n\n    accuracy = correct.float() / float(total)\n    out_loss = running_loss\n\n    return out_loss , accuracy, revenue\n\n\ndef evaluate(model: nn.Module, data_loader: DataLoader, loss_function: nn.modules.loss, device: torch.device):\n    model.eval()\n\n    with torch.no_grad():\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        revenue = 0\n\n        for data in data_loader:\n            inp, target = data[0].to(device), data[1].to(device)\n            output = model(inp)\n            loss = loss_function(output, target)\n\n            running_loss += loss\n\n            winners = output.argmax(dim=1)\n            correct += torch.sum((winners == target))\n            total += len(target)\n            revenue += calculate_revenue(output, target)\n\n        #out_loss = running_loss/len(data_loader)\n        accuracy = correct.float() / float(total)\n        out_loss = running_loss\n\n    return out_loss , accuracy, revenue","block_group":"ba372b7fb8104ee38d926b414229fd6d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"769398a77e4a4eb3abf23a52bc5d9bf0","source_hash":"6d848d41","execution_start":1655578145797,"execution_millis":2,"deepnote_cell_height":387,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"cost_matrix_np = np.array([\n    [5, -5, -5, 2],\n    [-5, 10, 2, -5],\n    [-5, 2, 10, -5],\n    [2, -5, -2, 5]\n    ])\n\ncost_matrix = torch.tensor([\n        [5, -5, -5, 2],\n        [-5, 10, 2, -5],\n        [-5, 2, 10, -5],\n        [2, -5, -2, 5]\n        ], device=device)\n\nscaler = MinMaxScaler()\ncost_matrix_transformed = cost_matrix\n#cost_matrix_transformed = torch.Tensor(scaler.fit_transform(cost_matrix_np))\n#cost_matrix_transformed = torch.nn.functional.normalize(torch.Tensor(cost_matrix))","block_group":"769398a77e4a4eb3abf23a52bc5d9bf0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f0140f225988453e8589ecccb85599e5","source_hash":"91e41c60","owner_user_id":"c6f73f6d-b02b-413f-a493-796763fa488b","is_code_hidden":false,"execution_start":1655578268351,"execution_millis":19596,"is_output_hidden":false,"deepnote_cell_height":1083.3125,"deepnote_output_heights":[null,611],"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"model = nn_classifier(n_features=X_train.shape[1])\nbaseline_clf = BaselineClassifier(y_tensor)\nmodel.to(device=device)\n\ncost_matrix = torch.tensor([\n        [5, -5, -5, 2],\n        [-5, 10, 2, -5],\n        [-5, 2, 10, -5],\n        [2, -5, -2, 5]\n        ], dtype=torch.float, device=device)\n\n#loss_function = CostLoss(cost_matrix)\n#loss_function = CostLossSingle(cost_matrix)\nloss_function = CostSensitiveRegularizedLoss(cost_matrix, 2)  # (-1.)*\n#loss_function = nn.CrossEntropyLoss()\nlr = 1e-4\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nepochs = 1000\ntrain_losses, train_accs, train_revs = [], [], []\ntest_losses, test_accs, test_revs = [], [], []\nbase_losses, base_accs, base_revs = [], [], []\n\nfor update in range(epochs):\n    train_loss, train_acc, train_rev = train(model, train_loader, optimizer, loss_function, device)\n    train_losses.append(train_loss.detach())\n    train_accs.append(train_acc.detach())\n    train_revs.append(train_rev.detach())\n\n    test_loss, test_acc, test_rev = evaluate(model, test_loader, loss_function, device)\n    test_losses.append(test_loss.detach())\n    test_accs.append(test_acc.detach())\n    test_revs.append(test_rev.detach())\n\n    baseline_loss, baseline_acc, baseline_rev = evaluate(baseline_clf, test_loader, loss_function, device)\n    base_losses.append(baseline_loss)\n    base_accs.append(baseline_acc)\n    base_revs.append(baseline_rev)\n\n    if update % 50 == 0:\n        print(f'############# Epoch:{update} ###############')\n        print(f'Training Loss: {train_loss:.2f}\\tTraining accuracy: {train_acc:.2f}\\tTraining Revenue: {train_rev:.2f}')\n        print(f'Test Loss: {test_loss:.2f}\\tTest accuracy: {test_acc:.2f}\\tTest Revenue: {test_rev:.2f}')\n    \nplot_training((train_losses, train_accs, train_revs), (test_losses, test_accs, test_revs), (base_losses, base_accs, base_revs))","block_group":"f0140f225988453e8589ecccb85599e5","execution_count":null,"outputs":[{"name":"stdout","text":"############# Epoch:0 ###############\nTraining Loss: 33.88\tTraining accuracy: 0.32\tTraining Revenue: 1445.00\nTest Loss: -87.91\tTest accuracy: 0.44\tTest Revenue: 1427.00\n############# Epoch:50 ###############\nTraining Loss: -22215906.00\tTraining accuracy: 0.42\tTraining Revenue: 3090.00\nTest Loss: -29221276.00\tTest accuracy: 0.41\tTest Revenue: 1165.00\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-15440e797da6>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-86-b4c770858103>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, loss_function, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-fe12a9f976e0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"5134f6da4fe340ef85b815a36ab79097","deepnote_cell_height":66,"deepnote_cell_type":"code"},"source":"","block_group":"5134f6da4fe340ef85b815a36ab79097","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e2905743-bdaf-45dd-a896-9824e6125426' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"1137ae7e781e4845b927ec09f7e70586","deepnote_execution_queue":[]}}